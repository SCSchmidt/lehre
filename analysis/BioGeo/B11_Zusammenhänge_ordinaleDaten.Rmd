---
title: "Nicht-paramterische Testverfahren"
author:
  - Sophie C. Schmidt:
      email: s.c.schmidt@uni-koeln.de
      correspondence: true
contributor: 
  - Sara Schiesberg
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  md_document:
    variant: markdown_github
always_allow_html: true
---

```{r setup, include=FALSE}
# Setup
knitr::opts_chunk$set(
  warning = FALSE,
  message = FALSE,
  comment = "#>",
  fig.path = "./figures/",
  fig.width = 5, 
  fig.height = 5)

# Daten und Pakete laden
library(palmerpenguins)
data(penguins)
```

# Nicht-parametrische Verfahren

Im folgenden werden nicht-parametrisch Testverfahren besprochen. Nicht-parametrisch bedeutet, dass die Daten nicht normalverteilt sein müssen, damit man den Test darauf anwenden kann. Es reicht außerdem, wenn die Daten ordinal skaliert sind.

## Vergleich zweier Gruppen

Hier geht es darum, zwei Gruppen zu vergleichen und zu schauen, ob sie eventuell aus der gleichen Grundgesamtheit stammen könnten oder ob die Unterschiede signifikant sind. 

### U-Test nach Mann-Whitney

Der U-Test ist geeignet für ordinale und metrische Variablen. 

Nehmen wir als erstes Beispiel das Gewicht der Pinguine und schauen, ob Männchen oder Weibchen einer Art unterschiedlich schwer sind. 

Der Test in R benutzt eine recht "alte" Syntax, die manchmal vorkommt. Mithilfe der Tilde "~" beschreibt er, welche zwei Variablen gegeneinander getestet werden sollen. `paired = FALSE` stellt sicher, dass wir hier den U-Test / Rangsummentest und nicht den Wilcoxon-Test für gebundene Stichproben berechnen.

```{r}
# Auswahl definieren
adelie <- subset(penguins, penguins$species == "Adelie") # zuerst einen neuen Datensatz nur mit der Art "Adelie" ersellen

# Test berechnen
wilcox.test(data = adelie, body_mass_g ~ sex, paired = FALSE) # Testberechnung: wilcox.test(data = df, ordinale od. metrische Variable ~ gruppierender Faktor, paired = FALSE)
```

Dass da `Wilcoxon rank sum test with continuity correction` steht, bedeutet, dass R erkannt hat, dass die Datensätze stetig (also metrisch) sind. Dann geht er im Hintergrund leicht anders damit um. Weitere Infos hier: <https://data.library.virginia.edu/the-wilcoxon-rank-sum-test/>. 

Der p-Wert ist wieder super klein, das heißt, die beiden Gruppen sind signifikant unterschiedlich!
Schauen wir uns das einmal an:

```{r box_adelie_gewicht_sex}
# Paket laden
library(ggplot2)

# Boxplot erstellen
ggplot(data = subset(adelie, !is.na(adelie$sex)), # Trick: Ich filtere bei "data" alle Datensätze raus, in denen in der Spalte "sex" NA steht
       aes(y = body_mass_g, x = sex, col = sex)) +
  geom_boxplot() 
```

Ich bin überzeugt. Das können wir wirklich stichhaltig interpretieren!

Ein anderes Beispiel, jetzt eins mit einer diskreten Variable.

Nehmen wir dafür den Piraten-Datensatz:

```{r}
# Pakte und Daten laden
library(yarrr)
data(pirates)
```

Die Piraten haben eine Anzahl von Tattoos. Das ist nun eine eindeutig diskrete Variable, denn es wird wohl kaum jemand mit einem halben Tatoo herumlaufen. Trotzdem ist sie als `numeric` abgelegt, was gut ist, da der `wilcox.test()` als Datentyp einen numerischen Vektor braucht.

Wir können jetzt schauen, ob die Zahl der Tattoos bei Piraten mit und ohne Bandana (`headband`) unterschiedlich ist. Das heißt:

```{r}
# Test berechnen
wilcox.test(data = pirates, tattoos ~ headband, paired = FALSE)
```

Wir haben einen sehr kleine p-Wert, schauen wir uns das doch noch einmal als Balkendiagramm an:

```{r bar_pirates_tattos_headband}
# Gestapeltes 
ggplot(data = pirates, 
       aes(x = tattoos, fill = headband)) + # mit fill gebe ich den Balken unterschiedliche Farben, sie werden dann "übereinander gestapelt"
  geom_bar() 
```

Das sieht doch fast wie ein Histogramm aus.

Aber Vorsicht! Es ist keins! Auf der x-Achse befindet sich eine diskrete Variable, diese sollte nicht als Histogramm dargestellt werden!

### Wilcoxon-Test

Im Unterschied zum U-Test ist der Wilcoxon-Test nur für abhängige Daten geeignet. Wir haben in unserem Datensatz kein Beispiel für abhängige Daten. Deshalb hier nur kurz der Code, solltet ihr solche Daten einmal bekommen. Eigentlich ganz einfach, der einzige Unterschied zum Mann-Whitney-Test ist die Angabe von `paired = TRUE`:

```
wilcox.test(data = df, metrische Variable ~ gruppierende, paired = TRUE)
```

### Kolmogorov-Smirnov-Test mit zwei Verteilungen:

Kriegen wir das gleiche Ergebnis mit dem K-S-Test?

Auch der K-S-Test ist geeignet für ordinale und metrische Verfahren.

Im Gegensatz zum wilcox-Test sieht die Syntax so aus:

```
ks.test(x = Werte der Gruppe 1, y = Werte der Gruppe 2)
```

Das heißt wir müssen noch einmal schnell die beiden Gruppen definieren:

```{r}
# Auswahl definieren
adelie_f <- subset(adelie, adelie$sex == "female")
adelie_m <- subset(adelie, adelie$sex == "male")
```

Jetzt können wir den Test machen:

```{r}
# Test berechnen
ks.test(adelie_m$body_mass_g, adelie_f$body_mass_g)
```

Ja! Klasse!  Ein winziger p-Wert.

Da steht zwar `im Falle von Bindungen sind die p-Werte approximativ` , was ein Warnhinweis ist, weil manche Werte mehrmals vorkommen, aber das ist bei einer großen Stichprobe recht häufig und kein Problem. Bei kleineren Stichproben sollte man mit dem Ergebnis dann vorsichtiger sein.

Dann schauen wir doch einmal, ob wir auch Gewichtsunterschiede zwischen den Spezies finden. Da dies drei Gruppen sind, können wir nicht mehr den K-S oder U-Test nehmen, sondern brauchen: 

## Vergleich zwischen mehr als zwei Gruppen

### Kruskal-Wallis

Die Syntax des Tests kennen wir schon vom `wilcox.test()`

```
kruskal.test(weight ~ group, data = my_data)
```

Im Unterschied zu dem U-Test kann man eine Kruskal-Wallis-Rangvarianzanalyse auch durchführen, um Unterschiede zwischen mehr als zwei Gruppen zu testen. Daher können wir dieses Testverfahren prima anwenden, um zu überprüfen, ob das Gewicht zwischen den 3 Pinguinarten signifikant variiert. Das sieht dann so aus:

```{r}
# Test berechnen
kruskal.test(body_mass_g ~ species, data = penguins)
```

Ok, der p-Wert ist wieder so klein, das ist auf jeden Fall klar, da sind signifikante Unterschiede zwischen den Gruppen. Aber hmh, es sind ja drei Gruppen. Sind sie alle zueinander gleich unterschiedlich? Vielleicht sind sich ja zwei Gruppen sehr ähnlich und nur die dritte ist anders.

Das können wir mit einer Funktion testen die `pairwise.wilcox.test()` heißt und eine paar-weisen Vergleich zwischen den Gruppen berechnet. 

```{r}
# Test berechnen
pairwise.wilcox.test(penguins$body_mass_g, penguins$species,
                 p.adjust.method = "BH") # p.adjust korrigiert für das Testen mit mehreren Gruppen. siehe: https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/p.adjust
```

Wenn man sich die Output-Tabelle anschaut, sieht man, dass nur Gentoo signifikant (p < 0.05 ) zu den beiden anderen Gruppen unterschiedlich ist. Der p-Wert beim Vergleich von Adelie- und Chinstrap-Pinguinen ist 0,49 und damit nicht signifikant.

Visualisieren wir das kurz als Boxplot, können wir das auch besser einschätzen:

```{r adelie_chinstrap_weight}
# Boxplot erstellen 
ggplot(data = penguins, 
       aes(x = species, y = body_mass_g)) +
  geom_boxplot(na.rm = TRUE)
```

Ja, Adelie und Chinstrap sehen ziemlich gleich schwer aus.

Herzlichen Glückwunsch, das war es auch schon zu den ordinalen Testverfahren!

**Aufgabe: Findet heraus, ob die drei Pinguin-spezies sich auch in ihrer "Flipper length" unterscheiden.**

**Nehmt den Kolmomogorov-Smirnov-Test, um herauszufinden, ob das Alter der Piraten sich unterscheidet, je nachdem auf welchem College sie waren**
