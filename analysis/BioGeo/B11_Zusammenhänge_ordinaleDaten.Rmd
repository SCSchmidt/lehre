---
title: "Zusammenhänge ordinaler Daten"
author: "Sophie C. Schmidt"
date: "14 7 2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



# Vergleich zweier Gruppen

Hier geht es darum, zwei Gruppen zu vergleichen und zu schauen, ob sie eventuell aus der gleichen Grundgesamtheit stammen könnten oder ob die Unterschiede signifikant sind. 

# Nicht-parametrische Verfahren

Nicht-parametrisch bedeutet, dass die Daten nicht normalverteilt sein müssen, damit man den Test darauf anwenden kann. Es reicht außerdem, wenn die Daten ordinal skaliert sind. 

## U-Test

Der U-Test ist geeignet für ordinale und metrische Variablen. 

Nehmen wir die das Gewicht der Pinguine und schauen, ob Männchen oder Weibchen unterschiedlich schwer sind. 


```{r}
m_penguins <- subset(penguins, sex == "male" )
w_penguins <- subset(penguins, sex == "female" )

wilcox.test(m_penguins$body_mass_g, w_penguins$body_mass_g)
```

Dass da `Wilcoxon rank sum test with continuity correction` steht, bedeutet, dass R erkannt hat, dass die Datensätze normalverteilt sind. Dann geht er im Hintergrund leicht anders damit um. Weitere Infos hier: <https://data.library.virginia.edu/the-wilcoxon-rank-sum-test/>. 

Der p-Wert ist wieder super klein, das heißt, die beiden Gruppen sind signifikant unterschiedlich!
Schauen wir uns das einmal an:

```{r}
ggplot(data = penguins)+
  geom_boxplot(aes(y = body_mass_g, x = sex, col = sex), na.rm=TRUE)
  
```
Ich bin überzeugt. Das können wir wirklich stichhaltig interpretieren!


### K-S-Test mit zwei Verteilungen:


Kriegen wir das gleiche Ergebnis mit dem K-S-Test?

Auch der K-S-Test ist geeignet für ordinale und metrische Verfahren.

```{r}
ks.test(m_penguins$body_mass_g, w_penguins$body_mass_g)

```

Ja! Klasse! 

Und zwar, obwohl sich in unserem Datensatz mehrere Spezies von Pinguinen verstecken. 

Dann schauen wir doch einmal, ob wir auch Unterschiede zwischen den Spezies finden. Da dies drei Gruppen sind, können wir nicht mehr den K-S oder U-Test nehmen, sondern brauchen: 

### Kruskal-Wallis

Der Kurskal-Wallis-Test in R benutzt eine recht "alte" Syntax, die manchmal vorkommt. Mithilfe der Tilde "~" beschreibt er, welche zwei Variablen gegeneinander getestet werden sollen.

```{r}
kruskal.test(weight ~ group, data = my_data)
```

Wenden wir das auf den Pinguin-Datensatz an, sieht das so aus:

```{r}
kruskal.test(body_mass_g ~ species, data = penguins)
```

Ok, der p-Wert ist wieder so klein, das ist auf jedenfall klar, da sind signifikante Unterschiede zwischen den Gruppen. Aber hmh, es sind ja drei Gruppen. Sind sie alle zueinander gleich unterschiedlich? Vielleicht sind sich ja zwei Gruppen sehr ähnlich und nur die dritte ist anders.

Das können wir mit einer Funktion testen die `pairwise.wilcox.test()` heißt und eine paar-weisen Vergleich zwischen den Gruppen berechnet. 

```{r}
pairwise.wilcox.test(penguins$body_mass_g, penguins$species,
                 p.adjust.method = "BH") # p.adjust korrigiert für das Testen mit mehreren Gruppen. siehe: https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/p.adjust
```


Wenn man sich die Output-Tabelle anschaut, sieht man, dass nur Gentoo signifikant (p < 0.05 ) zu den beiden anderen Gruppen unterschiedlich ist. Der p-Wert beim Vergleich von Adelie- und Chinstrap-Pinguinen ist 0,49 und damit nicht signifikant.

Visualisieren wir das kurz als Boxplot, können wir das auch besser einschätzen:

```{r}
ggplot()+
  geom_boxplot(data = penguins, aes(x = species, y = body_mass_g), na.rm = TRUE)
```
Ja, Adelie und Chinstrap sehen ziemlich gleich schwer aus.


# Parametrische Verfahren


## F-Test
Der F-Test vergleicht die Varianzen von metrischen Variablen. Schauen wir uns doch noch einmal die Höhe der BACups an:
```{r}
var.test(x = BACups_p$H,
         y = BACups_s$H,
         alternative = "two.sided")
```
Die Alternativhypothese ist, dass das Verhältnis der beiden Varianzen zueinander nicht 1 entspricht -- sie also unterschiedlich sind.

Allerdings lässt der p-Wert keine Annahme der Alternativhypothese zu... 


## t-test

Wir testen jetzt, ob sich die Mittelwerte so weit unterscheiden, dass wir von zwei unterschiedlichen Gruppen ausgehen können:
```{r}
t.test(x = BACups_p$H,
         y = BACups_s$H,
         alternative = "two.sided")
```
Es wurde ein Welch-Test durchgeführt, weil die Varianzen nicht gleich sind (auch wenn wir oben die Alternativhypothese nicht annehmen konnten, war das Ergebnis auch nicht eindeutig so, dass das Varianzverhältnis 1 entspricht).

Der p-Wert erlaubt es uns wieder nicht, die Alternativhypothese sicher anzunehmen.


Tcha. Das passiert manchmal.

Tatsächlich haben wir in der Archäologie selten normalverteilte Daten. Deswegen sind der Mann-Whitney-Test und der K-S-Test wichtiger für uns.

