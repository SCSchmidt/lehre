---
title: "Multiple lineare Regression"
author:
  - Schmidt, Sophie C.
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
    bookdown::word_document2:
      fig_caption: yes
      reference_docx: "../templates/template.docx" # Insert path for the DOCX file
bibliography: references.bib
csl: "../templates/journal-of-archaeological-science.csl" # Insert path for the bib-style
---


```{r setup, include=TRUE}
knitr::opts_chunk$set(
  collapse = TRUE,
  warning = FALSE,
  message = FALSE,
  echo = TRUE,
  comment = "#>",
  fig.path = "../figures/",
  fig.width=6, 
  fig.height=6
)
```

Mithilfe der multiplen linearen Regression kann ich die Abhängigkeit einer metrischen Variable von mehreren anderen metrischen Variablen schätzen und zwar gleichzeitig und nicht einfach hintereinander.

Es gelten alle Voraussetzungen wie für die normale lineare Regression (d.h. eine lineare Beziehung zwischen den unabhängigen und der abhängigen Variable, Homoskedastizität, Normalverteilung der Residuen und Unabhängigkeit der Residuen).

Dabei müssen die unabhängigen Variablen auch von einander unabhängig sein (Problem der „Multikolinearität“)! Wenn zwei der unabhängigen Variablen stark miteinander korrelieren, kann das Modell nicht mehr herausfinden, welche der gegebenen unabhängigen Variablen einfluss auf die abhängige Variable hat.

Eine Gleichung für die multiple lineare regression sieht so aus: $ y = a + b_1 * x_1, + b_2 * x_2 + b_3 * x_3 ... $. 

Nehmen wir als Bsp zwei Variablen. Ich teste, ob die Größe der Piraten mit ihrer Anzahl von Tattoos zu tun hat: 

```{r}
library(yarrr)
data("pirates")
pirates <- subset(pirates, pirates$sex == "male")

cor(pirates$tattoos, pirates$height, method = "pearson")

```
und stelle fest: Nein.

Diese beiden Werte möchte ich jetzt nehmen und schauen, ob sie mit der Länge der Bärte zusammenhängen:

```{r}
model1 <- lm(beard.length ~ tattoos + height, data = pirates)

summary(model1)
```

R erklärt uns wieder, welche Berechnung wir da vorgenommen haben, dann die Verteilung der Residueen (das sieht doch recht gleichmäßig aus, sehr gut) und im Anschluss die Koeffizienten-Schätzung mit Standardabweichung, t-Wert und Wahrscheinlichkeit. 



Wir haben es also mit einer Korrelation von Tattoos und Größe mit Bartlänge zu tun, die dieser Formel folgt: $beard.length = -64.87 + 0.59*tattoos + 0.41*height$

Daraus können wir uns auch die Konfidenzintervalle anzeigen lassen:

```{r}
confint(model1)

```

Und so die Bereiche abschätzen, in denen die Regressionslinie mit einer sehr hohen Wahrscheinlichkeit liegt. Man kann das noch visualisieren, in dem man die beiden unabhängigen Variablen normalisiert. Sie liegen ja in unterschiedlichen Bereichen (Tattoos sind deutlich kleinere Werte als Größe) und können deshalb nicht einfach nur übereinander geplottet werden. Mit der Funktion `scale` normalisiere ich Wertereihen, d.h. jeder Wert wird von dem Mittelwert abgezogen und und durch die Standardabweichung geteilt (sog. z-Transformation). Das kann ich als x- und die Bartlänge als y in der Grafik abtragen, die Tattoo-Anzahlen rot einfärben und dann eine "normale" lineare Regression für jeden der beiden Werte berechnen lassen (`geom_smooth` mit `model = "lm",formula = y ~ x` ) und diese unterschiedliche einfärben.



```{r}
ggplot(data = pirates)+
  geom_point(aes(x = scale(height), # normalisiere Größe
                 y = beard.length))+ 
  geom_point(aes(x = scale(tattoos), # normalisiere Anzahl Tattoos
                 y = beard.length),
             col = "red") +  # färbe Anzahl Tattoos rot ein
  geom_smooth(aes(x = scale(height), # erste lineare regression für Größe
                  y = beard.length),
              model = "lm",
              formula = y ~ x,
              col = "blue") +  # blau
  geom_smooth(aes(x = scale(tattoos), # zweite lineare regression für Tattoos
                  y = beard.length),
              model = "lm",
              formula = y ~ x,
              col = "green") + # eingefärbt grün
  xlab("normierte Größe und Tattooanzahl") + 
   ylab("Bartlänge")
```


https://wgruber.github.io/Modellbildung2/multiple-regression.html#voraussetzungen-mlr

Residualanalyse
...

Nun haben wir natürlich eigentlich noch Frauen im Datensatz, die eine Bartlänge von 0 haben. Das könnte uns das Ergebnis ganz schön verzerren.

**Aufgabe** Nehmt noch einmal nur die männlichen Piraten und überprüft, ob sich das Modell deutlich verändert! 
