---
title: "Zusammenhänge ordinaler Daten"
author: "Sophie C. Schmidt"
date: "14 7 2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      eval = FALSE)

library(palmerpenguins)
data(penguins)

```



# Vergleich zweier Gruppen

Hier geht es darum, zwei Gruppen zu vergleichen und zu schauen, ob sie eventuell aus der gleichen Grundgesamtheit stammen könnten oder ob die Unterschiede signifikant sind. 

# parametrische Verfahren

Parametrisch bedeutet, dass die Daten  ein metrisches Skalenniveau haben und **normalverteilt sein müssen**, damit man den Test darauf anwenden kann.


## F-Test
Der F-Test vergleicht die Varianzen von metrischen Variablen. Schauen wir uns doch noch einmal die Flossenlänge unserer Pinguine an und differenzieren sie nach Geschlecht. 

```{r}
# zwei Datensätze nach Geschlecht trennen:

penguins_f <- subset(penguins, penguins$sex == "female")
penguins_m <- subset(penguins, penguins$sex == "male")

```

Der F-Test ist in `base` R vorprogrammiert und die Funktion heißt `var.test`. 

```{r}
var.test(x = penguins_f$flipper_length_mm,
         y = penguins_m$flipper_length_mm,
         alternative = "two.sided")
```
Die Alternativhypothese ist, dass das Verhältnis der beiden Varianzen zueinander nicht 1 entspricht -- sie also unterschiedlich sind.

Der p-Wert "kratzt" mit 0,052 an der Grenze zur Signifikanz. Wenn wir die Signifikanzniveaus also nicht als trennscharf sonder eher "Richtlinien" verstehen, können wir hier sagen, dass es hier vielleicht doch signifikante Unterschiede zwischen den zwei Gruppen gibt.

Wir wissen ja, was ein Problem sein wird: Wir haben mehrere Pinguinarten in unserer Stichprobe. Vllt nehmen wir deshalb doch mal lieber nur die Pinguine einer Art.

```{r}
gentoo <- subset(penguins, penguins$species == "Gentoo") 
```

So kann ich auch gleich noch eine zweite Art und weise demonstrieren, wie der Code der Funktion auch aussehen kann:

```{r}
var.test(flipper_length_mm ~ sex, na.rm = TRUE, data = gentoo)
```

Dieser p-Wert ist sehr klein. Wir können also sicher davon ausgehen, dass die Varianz der beiden Gruppen nicht gleich ist.

Schauen wir uns das doch noch einmal visualisiert an, das hilft meistens bei der Intepretation. Ein Boxplot zeichnet ja immer das 1. und 3. Quartil ab und kann deshalb als Annäherung an die Standardabweichung bezeichnet werden:

```{r}
library(ggplot2)

ggplot()+
geom_boxplot(data = gentoo, 
               aes(y=flipper_length_mm, 
                   x = sex))
```
Ja, die beiden "boxes" sind doch deutlich unterschiedlich groß und stark voneinander verschoben.

Nehmen wir noch einmal ein anderes Beispiel: Das Gewicht, das war doch schon einmal eine Aufgabe.

Ach ja, trennen wir mal die Geschlechter vorher, schließlich heißt die Voraussetzung, dass der gemessene Parameter in beiden Gruppen normalverteilt sein soll. 

Also: 1. Ein subset nach dem Geschlecht der Tiere machen und 2. dann den Shapiro-Wilk-Test für die beiden Gruppen. 

```{r}

gentoo_f  <- subset(gentoo, gentoo$sex == "female")
gentoo_m  <- subset(gentoo, gentoo$sex == "male")


shapiro.test(gentoo_f$body_mass_g)
shapiro.test(gentoo_m$body_mass_g)

```

Sehr gut, diese beiden Variablen sind normalverteilt. Jetzt der F-Test:

```{r}
var.test(data = gentoo, body_mass_g ~ sex, na.rm = TRUE)
```

Der p-Wert ist relativ groß. Das bedeutet, die Varianz der beiden Gruppen ist recht sicher gleich.

Machen wir also mit diesem Bsp jetzt den t-Test:

## t-test

http://www.sthda.com/english/wiki/unpaired-two-samples-t-test-in-r

Wir testen jetzt, ob sich die Mittelwerte so weit unterscheiden, dass wir von zwei unterschiedlichen Gruppen ausgehen können:
```{r}
t.test(data = gentoo, body_mass_g ~ sex, na.rm = TRUE,
         alternative = "two.sided")
```

Es wurde ein Welch-Test durchgeführt, weil R die Varianz der Grundgesamtheit noch aus der Varianz der Stichproben errechnet.

Der p-Wert erlaubt es uns, die Alternativhypothese sicher anzunehmen.

Jetzt erweitern wir das Spektrum der Gruppen. Durch einen Faktor getrennt, der aber mehr als nur 2 Ausprägungenannehmen kann, können zB durch den Faktor "species" drei Gruppen entstehen. Bevor wir diese jedoch auf ihren Mittelwertsunterschied testen können, müssen wir auch hier die Varianzgleichheit untersuchen:

## Levene-Test
https://www.bjoernwalther.com/levene-test-in-r-berechnen-und-interpretieren/

Der Levene-Test ist im Paket "car" umgesetzt.

```{r}
install.packages("car")

library (car)
```

```{r}
leveneTest(data = penguins, body_mass_g ~ species, na.rm = TRUE)
```
Ein sehr kleiner p-Wert sagt: Ja. Diese Gruppen haben alle die gleiche Varianz.

Weiter damit zur einfaktoriellen ANOVA!


## einfaktorielle ANOVA

Die ANOVA ist bereits in `base` umgesetzt, mit der Funktion `aov`.

Aus irgendwelchen Gründen wir bei der ANOVA das Ergebnis nicht gleich angezeigt (also der p-Wert). Deswegen weisen wir das Ergebnis der eigentlichen Test-Berechnung einer Variablen zu und lassen uns dann das Ergebnis zusammengefasst ausgeben:

```{r}
# eigentliche ANOVAberechnung
res.aov <- aov(body_mass_g ~ species, data = penguins)

# Zusammenfassung des Ergebnisses
summary(res.aov)

```

Höchstsignifikant! Das bedeutet? Die Art hat einen Einfluss auf das Gewicht der Pinguine. 

Wer hätte es gedacht. ;-)

## mehrfaktorielle ANOVA

Eine mehrfaktorielle ANOVA ist in R relativ aufwändig. 

Wir rechnen hier deshalb nur eine zwei-faktorielle ANOVA. Wer mehr wissen will, schaue hier, das ist eine super Anleitung, wie man ANOVAs in R berechnet: <https://www.datanovia.com/en/lessons/anova-in-r/>

Wir könnten untersuchen, ob bei den Piraten die Größe von Geschlecht und dem College abhängt.

Als erstes checken wir alle Voraussetzungen: 

1. Sind die Daten in den jeweiligen Gruppen normalverteilt?

Machen wir hier also ein QQ-plot für alle Werte gleichzeitig:

```{r}
library(ggpubr)

ggqqplot(pirates, "height", ggtheme = theme_bw()) +
  facet_grid(college ~ sex)
```

Ja, das sieht doch ganz gut aus insgesamt.

Testen wir also als nächstes, ob

2. die Varianz in den Gruppen gleich ist.

Dafür nehmen wir den leveneTest aus dem Paket `car`. Wir stellen die abhängige metrische Variablen den beiden kategorialen Faktoren gegenüber:

```{r}
library(car)

# leveneTest(abhängige Variable ~ Faktor1*Faktor2, data = df)
leveneTest(height ~ sex*college, data = pirates)

```

Die Wahrscheinlichkeit steht unter `Pr(>F)` und liegt deutlich über 0,05. Wir können also von einer Varianzgleichheit ausgehen.

Dann also jetzt die ANOVA. Wie oben geben wir die Berechnung erst in eine Variable und lassen uns das Ergebnis dann zusammengefasst ausgeben:

```{r}
res.aov <- aov(height ~ sex * college, data = pirates)
summary(res.aov)
```

Interpretieren wir das Ergebnis: 

```
             Df Sum Sq Mean Sq F value Pr(>F)    
sex           2  46298   23149 215.290 <2e-16 ***
college       1     69      69   0.638  0.425    
sex:college   2     26      13   0.119  0.887    
Residuals   994 106879     108                   
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1      2         1           2       994
```
Wir sehen hier in der ersten Spalte die Faktoren, in der zweiten die "degrees of freedom", die Freiheitsgrade, in der dritten die "Sum of Squares" -- erinnert euch an die Vorlesung, das war die Abweichung der Messungen zum Gesamtmittelwert, die "mittlere sum of squares", den F-Wert und die Wahrscheinlichkeit, dass dieser Faktor einen Einfluss hat.
Ganz klar: Das Geschlecht hat einen großen Einfluss, aber das College nicht. 

Schauen wir uns das einmal an, plotten wir doch einfach die Körpergröße der Piraten in einem Boxplot nach College und Geschlecht:

```{r}
ggplot(data = pirates)+
  geom_boxplot(aes(x = college,
                   col = sex,#
                   y = height))
```
Ja. Die Unterschiede zwischen den Colleges sind sehr viel  kleiner als zwischen den Geschlechtern.


Sehr gut! Wir haben in diesem Kapitel untersucht, wie metrische Variablen eventuell von gruppierenden Faktoren abhängig sein können und wie wir das testen. 

**Aufgabe: Als Übung versucht doch das gleiche noch einmal herauszufinden für das Gewicht der Piraten. Hängt das Gewicht vom College oder dem Geschlecht ab? **

## multivariate Analysis of Variance

Jetzt schauen wir, wie mehrere abhängige Variablen gleichtzeitig untersucht werden können.

Hängen Größe und Gewicht von dem Geschlecht ab?

Dazu benutzen wir die Funktion `manova`, so wird die multivariate Varianzanalyse auch meistens abgekürzt.

wir fügen beide Variablen mit einem cbind (column bind) zusammen und setzen diese mit der Tilde gegenüber den Faktor Geschlecht. Wie auch vorhin wird das Ergebnis einer Variablen zugewiesen und dann mit `summary` ausgegeben. 
```{r}
library(yarrr)
data(pirates)

res.man <- manova(cbind(height, weight) ~ sex, data = pirates)

summary(res.man)
```
Wir haben eine hochsignifikanten Zusammenhang! 

Mit einem speziellen summary-Befehl können wir uns die Details ansehen:


```{r}
summary.aov(res.man)
```
Erst wird uns "response height", also die Ergebnisse für die Größe und dann "response weight", die Ergebnisse für das Gewicht angezeigt. Wir sehen unterschiede in den absoluten Werten, aber hochsignifikant sind beide.

Wie ist das mit der Spezies, den Pinguinen, ihrer Flipper-Length und dem Gewicht?

**Aufgabe: Berechnet und interpretiert eine multivariate ANOVA für das Gewicht der Pinguine und ihrer Flossenlänge in Abhängigkeit von der Spezies!**



