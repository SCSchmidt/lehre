---
title: "Lösungsskripte"
author: "Sophie C. Schmidt"
date: "17 8 2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Lösung Pearson Bravais R


```{r}
 cor.test(penguins$bill_depth_mm, penguins$bill_length_mm, method = "pearson", alternative = "two.sided")
```

## Lösung lineare Regression


```{r}
library(palmerpenguins)
data("penguins")
library(magrittr)
library(tidyr)
library(dplyr)
library(ggplot2)
library(ggpmisc)


penguins %>%
  filter(species == "Chinstrap") %>%
ggplot()+
  geom_point(aes(x = bill_depth_mm, y = bill_length_mm))+
  geom_smooth(aes(x = bill_depth_mm, y = bill_length_mm), method = "lm",
              se = FALSE)+
  stat_poly_eq(aes(x = bill_depth_mm, y = bill_length_mm, 
                   label =  paste(..eq.label.., 
                                  ..adj.rr.label..,
                                  sep = "~~~~")),
               formula = y~x, # y sei die abhängige Variable
               parse = TRUE,
               size = 3,
               label.y.npc = 0.7)+
    stat_fit_glance(         # p-value 
                  aes(x = bill_depth_mm, 
                      y = bill_length_mm,
                      label = paste("p-value: ",
                                    signif(..p.value.., 
                                           digits = 5))),
                  label.y.npc = 0.7,
                  size = 5,
                  color = "gray50", 
                  method = "lm", 
                  method.args = list(formula = y ~ x),
                  geom = "text")
```

## Lösung multiple lineare Regression (B16)


```{r}
library(yarrr)
data("pirates")
pirates <- subset(pirates, pirates$sex == "male")

cor(pirates$tattoos, pirates$height, method = "pearson")

```

```{r}
model1 <- lm(beard.length ~ tattoos + height, data = pirates)

summary(model1)
```


```{r}
confint(model1)
```


```{r multip_lin_reg}
  rockchalk::plotPlane(model = model1, plotx1 = "tattoos", plotx2 = "height")
```


## Residualanalyse

Genau wie bei der "normalen" linearen Regression können wir Residualanalyse betreiben:

### Q-Q-Plot

```{r qq_model1_res}
library(ggpubr)
ggqqplot(model1$residuals)
```

### Residuen und vorhergesagte Werte (residuals vs fitted)

```{r fitted_vs_residuals_model1}
plot(model1, which=1, col=c("blue")) # Residuals vs Fitted Plot
```

### "Scale-Location"


```{r homoskedas_model1}
plot(model1, which=3, col=c("blue"))  # Scale-Location Plot
```
Auch das ist überzeugend. Sehr schön! 


## Lösung Aufgabe logistische Regression (B 17)

```{r}
library(palmerpenguins)
data("penguins")

penguins <- subset(penguins, penguins$species == "Gentoo")
penguins$sex <-  as.character(penguins$sex) # das muss sein, weil ich einem Faktor keine anderen Werte geben kann als die, die vorher definiert wurden (female und male)
penguins$sex[penguins$sex == "female"] <- "0"
penguins$sex[penguins$sex != "0"] <- "1"

penguins$sex <- as.numeric(as.character(penguins$sex))

```

2. Logit berechnen: 

**Aufgabe** Füllt diese Syntax aus und berechnet das logit!
```

mylogit <- glm(sex ~ body_mass_g + flipper_length_mm, data = penguins, family = "binomial")

```
3. **Aufgabe** Die Summary-Statistik des Logit auswerfen lassen:

```{r}


summary(mylogit)

```


4. **Aufgabe:** Diskutiert die Ergebnisse in eurer Gruppe!
Was sagt das Estimate? Wie signifikant sind die Ergebnisse? 

5. **Aufgabe:** Berechnet die Veränderung der Chance, wenn das Gewicht zwischen 4000-5000 oder 5000 - 6000 liegt, die Länge der Flossen aber der Mittelwert bleibt.

Denkt daran, die Syntax von values trennt die Werte der beiden Parameter mit Semikolon, aber die Spezifizierung der Schritte der Werte des ersten Parameter muss mit Komma von dem Parameterwerten getrennt werden. Es gibt die Möglichkeit, den Mittelwert eines Parameters festzulegen, indem an seine Stelle `mean` schreibt: `values = "Spannbreite d. 1. Parameters den ich betrachten möchte,Schritte für Gruppenbildung;Mittelwert 2. Parameters"`

```{r}
library(glm.predict)
predicts(model = mylogit, values = "4000-6000,1000;mean", position = 1) 

```

Wie kann man dieses Ergebnis diskutieren?

Jetzt berechnet noch die odds Ratio 

```{r}
exp(coef(mylogit))
```

und visualisieren den Faktor Gewicht:

```{r}

library(ggplot2)
  ggplot(data = penguins, 
         aes(body_mass_g , # logit-modell unabhängige Variable
             sex)) + # abhängige variable
  geom_point(alpha = 0.2) + # Transparenz
  geom_smooth(method = "glm", # Methode
              method.args = list(family = "binomial")) + # binomial angeben
  labs(title = "Logistic Regression Model",  # Beschriftungen
       x = "in Abhängigkeit von Gewicht", 
       y = "Chance Männchen zu sein")


```


http://www.dwoll.de/r/gddmr_ed2/08_glm.pdf 

https://stats.idre.ucla.edu/r/dae/logit-regression/ 

https://stats.stackexchange.com/questions/86351/interpretation-of-rs-output-for-binomial-regression

<a href="http://www.dwoll.de/r/gddmr_ed2/08_glm.pdf" class="uri">http://www.dwoll.de/r/gddmr_ed2/08_glm.pdf</a>

<a href="https://stats.idre.ucla.edu/r/dae/logit-regression/" class="uri">https://stats.idre.ucla.edu/r/dae/logit-regression/</a>

<a href="https://stats.stackexchange.com/questions/86351/interpretation-of-rs-output-for-binomial-regression" class="uri">https://stats.stackexchange.com/questions/86351/interpretation-of-rs-output-for-binomial-regression</a> 

## Lösung Aufgabe Lineare Diskriminanzanalyse (B18)



**Aufgabe** Berechnet eine LDA für die Vorhersagbarkeit der Pinguin-spezies anhand von Flügelmaß, der zwei Schnabelmaße und Gewicht. Bereinigt den Datensatz von NA - Werten und benutzt einen Trainingsdatensatz, in dem 70% der Daten enthalten sind.

```{r}
library(palmerpenguins)
data("penguins")

pen <- penguins[,c(1,3:6)]

pen <-na.omit(pen)


train <- sample(nrow(pen), size = 0.7*nrow(pen)) # so erstelle ich einen Vektor aus zufällig gewählte Zahlen von 0 bis der Anzahl von Datensätzen im Piratendatensatz in der Größe von von 75% aus der Anzahl von Datensätzen im Piratendatensatz. Ich bekomme also einen Vektor namens "train" mit 750 Zahlen, die zufällig aus dem Bereich von 0 bis 1000 ausgewählt wurden. 

train_pen.df <- as.data.frame(pen[train, ]) # hiermit wähle ich mithilfe der Zufallswerte zufällige Zeilen aus dem Piratendatensatz aus

test_pen.df <- as.data.frame(pen[-train, ]) # hiermit nehme ich die Zeilen aus dem Datensatz, die nicht mit dem Zufallsvektor angesprochen werden (-train)

## train_pir.df + test_pir.df = pirates


# die Parameter werden geschätzt
preproc.param <- train_pen.df %>% 
  preProcess(method = c("center", "scale"))

# anhand der geschätzten Parameter werden die Daten transfomiert (Funktion "predict")
# 1. der Trainingsdatensatz
train.transformed <- preproc.param %>% 
  predict(train_pen.df) 

# 2. der Testdatensatz
test.transformed <- preproc.param %>% 
  predict(test_pen.df)

model <- lda(species~., data = train.transformed)

model
```


```{r}
plot(model)


# Vorhersage berechnen
predictions_lda <- model %>% 
  predict(test.transformed)

# Model accuracy
mean(predictions_lda$class == test.transformed$species)
```

Links zu weiteren Hilfestellungen:
<https://www.faes.de/Basis/Basis-Lexikon/Basis-Lexikon-Multivariate/Basis-Lexikon-Diskriminanz/basis-lexikon-diskriminanz.html>

<http://www.sthda.com/english/articles/36-classification-methods-essentials/146-discriminant-analysis-essentials-in-r/>

<https://www.statistik.tu-dortmund.de/fileadmin/user_upload/Lehrstuehle/Datenanalyse/Wissensentdeckung/Wissensentdeckung-Li-5_2x2.pdf>


## Lösung zu metrische multidimensionsale Skalierung (B19)

**Aufgabe:** Wiederholt die Berechnung mit den Pinguinen, Gewicht, Schnabelmaßen und Flossenmaß. Visualisiert das Ergebnis und färbt die Punkte nach Spezies ein.


```{r}


library(palmerpenguins)
data("penguins")

pen <- na.omit(penguins)

pen_m <- pen[,c(3:6)]


# Cmpute MDS
mds <- pen_m %>%
  dist() %>%          
  cmdscale() %>%
  as_tibble()
colnames(mds) <- c("Dim.1", "Dim.2")


# Plot MDS

mds_sp <- cbind(mds, pen)



library(ggplot2)

ggplot(data =  mds_sp)+
  geom_point(aes(x = Dim.1,
             y = Dim.2,
             col = species))

```

**Zusatzaufgabe**: Berechnet k-means für k = 2 oder 3, je nachdem, was ihr für sinnvoll haltet und stellt das in einem anderen plot als dem ersten dar.



```{r}
clust <- kmeans(mds, 3)$cluster %>% # auf mds wird kmeans berechnet mit k = 2
  as.factor() # und diese Clusterzuweisung wird als Faktor-Vektor gespeichert

mds_c <- mds_sp %>%         # wir erstellen mds_c aus mds_pir
  mutate(groups = clust)    # und weisen die Gruppen als eigene Spalte zu
```


Jetzt können wir folgendes machen: Die Punkte werden nach Dimension 1 und 2 geplottet, die Form der Punkte (shape) gibt das Geschlecht an und die Gruppen, wie sie von k-means erkannt wurden, werden farblich dargestellt und umrandet.

```{r}
ggscatter(mds_c, x = "Dim.1", y = "Dim.2",  #Punkte zeichnen
          shape = "species",                    # Form der Punkte nach Geschlecht
          color = "groups",              # Farbe nach Gruppen von k-means
          palette = "jco",               # Farbauswahl
          size = 1.5,                    # Größe der Punkte
          ellipse = TRUE,               # wir zeichnen eine Ellipse
          ellipse.type = "convex",     # konvex um die Gruppen herum
          repel = TRUE)               # Punkte sollen sich nicht überlagern
```
