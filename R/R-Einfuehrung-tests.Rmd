---
title: "Recap des 2. Seminarblocks zu R"
author:
  - Schmidt, Sophie C.
output: bookdown::word_document2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      message = FALSE)

#install.packages("bookdown") # Achtung. install.packages-Befehle können in einem RMD-Dokument nicht ausgeführt werden. Deswegen werden sie auskommentiert!
library(bookdown) # bookdown wird im output-Befehl ganz oben gebraucht. Deswegen bitte installieren!

#install.packages("knitr")
library(knitr)

```

## R Markdown

R Markdown kann Code chunks (also Blöcke mit R-code) und normalen Text zusammen verarbeiten. Ein RMD-Dokument kann dabei in eine html-Datei, in eine docx oder in eine pdf verwandelt werden. Das passiert mit dem "knit"-Knopf oder über Strg+Shift+K, wenn man das Paket "knitr" installiert hat. Achtung! Für DIESES Dokument muss außerdem "bookdown" installiert werden!


```{r Datenladen, warning=FALSE}
#install.packages("yarrr")
library(yarrr)
pirates <- pirates

```

Ein Codeblock beginnt mit drei Gravis (https://de.wikipedia.org/wiki/Gravis_(Typografie)), die sehen aus wie Hochkommas, liegen auf der Tastatur aber neben dem "zurück"-Pfeil. Danach kommt in geschweifte Klammern ({} - die macht man mit AltGr + 7 bzw 0) erst "r" und dann der Name des Codeblocks und wenn man möchte noch weitere Angaben, wie er in das Endformat übertragen werden soll (genaueres dazu gibt es hier: https://rmarkdown.rstudio.com/lesson-3.html)

## We want to test things!

Yarrr! Let's test. 

### Chi-Quadrat
Am Anfang ahben wir den chi-Quadrat-Test gemacht. Wir waren etwas verwirrt, deswegen nochmal eine Zusammenfassung:

```{r chi sex - headband}

ch <- chisq.test(x = table(pirates$sex, 
                     pirates$headband))
# Zuweisung des gesamten Testes zu ch
# x muss eine table sein! 
ch
# ch angucken = Testergebnis anzeigen lassen
# in ch sind aber noch alle anderen Sachen gespeichert, die zur Berechnung des Wertes nötig waren (das lässt sich gut in der "environment" oben rechts anschauen. Einfach auf den blauen Pfeil klicken, der neben "ch" steht und dann klappt sich ein Baum mit all den Angaben auf, die noch in ch gespeichert sind. ZB:

ch$expected
# damit kann ich mir die Erwartungswerte anzeigen lassen - sehr praktisch zur Einschätzung des chi-Quadrat-Tests! 

```

Das Ergebnis des Chi-Quadrat-Tests ist folgendes. Der Chi²-Wert ist `r ch$statistic `, der p-Wert ist `r ch$p.value ` bei einem Freiheitsgrad von `r ch$parameter `. (Whoaaaa, schaut euch das an, wenn ihr das Dokument "strickt", dann steht da nicht dieses komische mit dem r und so, sondern die richtigen Zahlen! Was ist geschehen? Das hier ist ein "in-text" code chunk. Er beginnt mi einem Gravis und "r" und endet mit einem Gravis. Ich kann also in meinem Fließtext auf einzelne Zahlen und Werte als Code zugreifen. Das heißt, ich vertipp mich nicht, wenn ich die Zahl übertrage und wenn ich irgendetwas in meinen Daten ändern muss, kann ich die Zahlen in dem Text trotzdem unverändert lassen, weil die richtige neue Berechnung angezeigt wird.)


Der angegebene p-wert ist unsere **Irrtumswahrscheinlichkeit** mit der wir die Alternativhypothese annehmen können. 
Zur Förderung der nicht-Verwirrung schaut einmal hier für Werte des **Konfidenzintervalls**: http://eswf.uni-koeln.de/glossar/chivert.htm 
Während das hier die typisch englische Schreibweise mit der **Irrtumswahrscheinlichkeit** ist: https://www.medcalc.org/manual/chi-square-table.php 

R spricht englisch. Deswegen gibt er mit p die Irrtumswahrscheinlichkeit an. Das hatte ich letztes mal etwas verscheppert, tut mir leid.

Wir können also bei diesem Beispiel ziemlich sicher sein, dass die männlichen und weiblichen Piraten Kopftücher bevorzugen, während die trans*odersonstwas Piraten das nicht so gerne tun (Vergleich der Erwartungswerte und der beobachteten Werte zeigt, wie der Zusammenhang aussieht).


Man kann auch einen einzelnen Wert anschauen und berechnen, ob die Bevorzugung einer Universität statistisch signifikant ist:
```{r chi 2}

chisq.test(table(pirates$college))

```
Das ist super signifikant.

Ein drittes Beispiel: 

```{r chi, echo=FALSE}
# das mach ich etwas anders als im Unterricht, damit ihr eine etwas andere Schreibweise des gleichen Tests seht:

p_cs <- table(pirates$college, # hiermit weise ich dem Ausdruck "p_cs" die gesamte Pivot-Tabelle aus College und Sex zu
      pirates$sex)

chisq.test(p_cs) # jetzt kann ich den Chi-Quadrat-Test auf den Ausdruck p_cs anwenden, da der ja für die Tabelle steht
```
Auch das ist der Hammer signifikant.


Ok, jetzt müssen wir nochmal schauen, wie stark der Zusammenhang ist.

```{r cramers v, echo=TRUE}

#install.packages("questionr") # das Paket brauche ich für Cramers V
library(questionr)

cv_cs <- cramer.v(table(pirates$college,
               pirates$sex))

```

Der Kontingenzkoeffizient Cramérs V ergibt eine Zusammenhangsstärke zwischen bevorzugtem College und dem Geschlecht der Piraten von `r cv_cs`. Das ist ein mittelstarker Zusammenhang (zur Interpretation von Cramérs V siehe: https://www.statistik-und-beratung.de/2015/07/effektstaerke/ ).


### Kolmogorov-Smirnov-Test

Weiter geht es mit dem KS-Test. Den brauchen wir, um zwei unterschiedliche Datensätze miteinander zu vergleichen. Das Skalenniveau muss mindestens ordinal sein. 

Dafür brauchen wir also als erstes zwei Datensätze:

```{r daten für KS}
f_pirates <- subset(pirates, sex == "female")
m_pirates <- subset(pirates, sex == "male")
# subsets: Wir nehmen nur die weiblichen und die männlichen Piraten 

```

Die Nullhypothese sagt, dass die beiden Datensätze gleich sind.
```{r ks height, echo=FALSE}

#install.packages("dgof")
library(dgof) # wir müssen das Paket installieren, da der KS-test nicht in base umgesetzt ist.

ks.test(x = f_pirates$height,
        y = m_pirates$height)

```
An dieser Stelle gibt es die Fehlermeldung "cannot compute correct p-values with ties" -  das liegt daran, dass es in den beiden Datensätzen Werte gibt, die doppelt auftreten. Damit kann der K-S-Test nicht gut umgehen.
Trotzdem ist das Ergebnis so höchstsignifikant, das selbst, wenn der p-Wert nicht ganz korrekt ist, das Ergebnis wohl trotzdem gelten kann: Wir können die Alternativhypothese mit großer Wahrscheinlichkeit annehmen, d.h. eine der beiden Gruppen ist größer als die andere.

Mit dem K-S-Test kann ich auch einen Test auf Normalverteilung durchführen. Hier war mir eine Sache durchgerutscht: Wenn ich meine Verteilung gegen die Normalverteilung testen will, muss ich die Normalverteilung an die gleiche Stelle "rücken" wie meine Verteilung. Das tu ich, indem ich ihr "meinen" Mittelwert gebe und "meine" Standardabweichung:

```{r ks as test auf normalverteilung}
ks.test(x = pirates$height,
        y = "pnorm", mean(pirates$height), sd(pirates$height))

# ks.test(mydata, pnorm, mean(mydata), sd(mydata) ) ist sozusagen eine "allgemeine Umschreibung der Syntax"

```
Jetzt bekomme ich nämlich den p-Wert von 0,67 heraus, was mir sagt, dass ich mit einer Wahrscheinlichkeit von 66,7% daneben liege, wenn ich die Alternativhypothese annehme. D.h. Ich hab eine ca. 66,7%ige Chance, dass, die Werte normalverteilt sind. Jetzt muss ich entscheiden, ob mir das reicht als Sicherheit oder ob ich sage, nee, es ist nicht signifikant, ich kann keine Aussage machen.

Was kann ich noch tun, um mein Ergebnis einzuschätzen?
Ich mal mir einfach manchmal schnell eine Grafik, um damit umgehen zu können:

```{r Dichtegrafik}
library(ggplot2)
ggplot()+
  stat_function(aes(x=120,220), fun = dnorm, n = 1000, args = list(mean = mean(pirates$height), sd = sd(pirates$height)), col="blue")+ # stat_function fügt eine bestimmte statistische Funktion hinzu. In dem Bereich x=120 bis 220 (das habe ich gewählt, weil sich die Piratengrößen so verteilen), mit der funktion fun = Dichte-Normalverteilung (dnorm), n = 1000 Wiederholungen, und den beiden wichtigen Werten: Mittelwert und Standardabweichung, die ich von unserer Piratenverteilung klaue, damit die beiden Darstellungen direkt übereinander liegen. Dann soll sie noch blau werden (col = blue)
  geom_density(data = pirates, aes(x = height)) # einfach hintendran die Dichte der Größenverteilung unserer Piraten
```
Wie man sieht: Die Abweichungen zur Normalverteilung sind doch deutlich. Die Größenverteilung der Piraten ist also zwar symmetrisch und unimodal, aber nicht perfekt normalverteilt.



### Weiter mit dem U-Test

Der U-Test war ja von vielen leuten entwickelt worden. Einer davon war Wilcoxon. So heißt der Test bei R "wilcox.test". Auch hier vergleichen wir die Größe der weiblichen und der männlichen Piraten.

```{r U-Test , echo=FALSE}

wilcox.test(x = f_pirates$height,
            y = m_pirates$height,
            alternative = "less") # die "alternative" gibt es in drei Möglichkeiten: "less" heißt Gruppe x ist kleiner als Gruppe y, "greater" Gruppe x sei größer als Gruppe y (das sind jeweils "gerichtete Hypothesen") und "two.sided": ich will nur wissen, ob es überhaupt einen Unterschied gibt, ich weiß noch nicht, in welche Richtung er geht.


```
Das ERgebnis ist wieder ein unheimlich kleiner p-Wert und die Alternativhypothese kann bestätigt werden: Es gibt einen Unterschied in der Größe zwischen den Männern und Frauen und zwar sind die Frauen kleiner als die Männer.

### einfacher Varianztest: F-Test

Der F-Test schaut ja, ob die Varianzen der beiden Gruppen gleich ist oder nicht. Er eignet sich nur für normalverteilte Daten. Wir nehmen jetzt einfach mal ungetestet die Gewichtsverteilung der Piraten.

```{r F-Test Gewicht}

var.test(x = f_pirates$weight,
         y = m_pirates$weight,
         alternative = "two.sided")# alternative kann man hier genauso benutzen wie bei dem wilcox.test
``` 
Wir haben einen F-Wert von rund 0,9, und dazu einen p-Wert von 0,23, das heißt, eine Irrtumswahrscheinlichkeit von 23%, dass wir die Alternativhypothese (die beiden Gruppen haben unterschiedliche Varianzen) annehmen können. Das Konfidenzintervall wird auch angegeben. Das heißt, mit 95% Sicherheit liegt der "wahre" F-Wert in der Grundgesamtheit zwischn 0,74 und 1,07. Die Tendenz geht also zu "ähnlichen" Varianzen.

Ein anderes Beispiel vielleicht:

```{r F-Test Größe }

var.test(x = f_pirates$height,
         y = m_pirates$height,
         alternative = "two.sided")


``` 
Hier ist F = 0,97, das ist schon fast 1. Das 95%-Konfidenzintervall liegt zwischen 0,81 und 1,16. Der p-Wert ist 0,74. Wir haben also, wenn wir die Nullhypothese annehmen (die beiden Gruppen haben die gleiche Varianz) eine Irrtumswahrscheinlichkeit von 26%. 

In beiden Fällen können wir keine ganz genaue Aussage mit einer der typischen Signifikanzschwellen von 5%, 1% und 0,1% machen sondern eher nur Tendenzen ausdrücken. In dem Fall hilft es m. E. mit den Konfidenzintervallen zu arbeiten. 

### t-Test

Wir hatten bei der Größe der Piraten eher die Chance, dass die Varianzen gleich sind als beim Gewicht, deswegen arbeiten wir damit weiter (eine Voraussetzung des t-Tests war die Varianzgleichheit!). 

```{r t-Test }
t.test(x = f_pirates$height,
         y = m_pirates$height,
         alternative = "two.sided")

``` 
Der Test gibt uns den t-Wert, Freiheitsgrad und p-Wert zurück. Wir können mit höchstsignifikanter Wahrscheinlichkeit annehmen, dass die Alternativhypothese angenommen werden kann. Das 95%-Intervall gibt an, wie groß der Unterschied des Mittelwerts mit 95%er Wahrscheinlichkeit wirklich ist: Er liegt zwischen 15,26 und 12,61. 

### Korrelationskoeffizient


Pearson's Korrelationskoeffizient wird zwischen zwei Variablen eines Datensatzes wie folgt berechnet:
```{r cor}
cor.test(pirates$height, pirates$weight, method = "pearson")

```
Das Ergebnis ist, statistisch höchstsignifikant, ein R-Wert von 0,93. Das ergibt eine sehr starke Korrelation zwischen Größe und Gewicht der Piraten. Auch hier wird ein Konfidenzintervall errechnet, welches sehr eng ist (zwischen 0,92 und 0,94).

## Lineare Regression

Für die lineare Regression installieren wir ggplot und ggpmisc, da wir sie direkt visualisieren wollen, nicht nur berechnen.

```{r lin reg}

#install.packages("ggplot2")
library(ggplot2)
#install.packages("ggpmisc")
library(ggpmisc)


ggplot(data = pirates)+
  geom_point(aes(x = weight, y = height))+ # Punktverteilung von Gewicht und Größe der Piraten
  geom_smooth(aes(x = weight, y = height), # wir arbeiten mit Gewicht und Größe
              method = "lm", # Methode = linear model, da kann man auch andere Berechnungen angeben
              se = FALSE)+ # se ist der "standard error", also das Konfidenzintervall, welches mit TRUE angeschaltet werden kann (anstelle von FALSE)
  stat_poly_eq(data = pirates, # hiermit lassen wir uns die Gleichung der linearen Regression anzeigen
               aes(x = weight, y = height, # wir sagen ihm wieder, womit wir rechnen
                   label = paste(..eq.label.., # Formelgleichung hineinkopieren
                                 ..adj.rr.label.., # R²-Wert hineinkopieren
                                 sep = "~~~~")), # Trenn die beiden mit so vielen Leerzeichen wie Tilden angegeben wurden
               formula = y~x, # nimm eine Formel die x und y direkt linear verknüpft
               parse = TRUE)+ # zeig alles an
  stat_fit_glance(data = pirates, # jetzt das gleiche für den P-Wert
                  aes(x = weight, y = height, # wir sagen ihm wieder, womit wir rechnen
                      label = paste("p-Wert:", # kopier die Schrift "p-Wert" hinein
                                    signif(..p.value.., # singifikante Werte - den p-Wert
                                           digits = 4))), #  mit 4 Nachkommastellen bitte
                  label.y.npc = 0.9, # schreib das ganze auf der y-Achse an die 0,9-Marke (90% der Höhe), damit es sich nicht mit der Gleichung überschneidet
                  method = "lm", # Die Berechnungsangabe wie oben
                  method.args = list(formula = y~x),
                  geom = "text") # es ist übrigens Text, was du da einfügst.


``` 

Wir haben also eine Gerade durch die Punktwolke gelegt, die den sehr guten R²-Wert von 0,87 aufweist. Der p-Wert ist so klein, dass er nur als 0 angezeigt wird. Es ist also höchstsignifikant.


## Herzlichen Glückwunsch! Das war echt viel und ihr habt das alles mitgemacht!


```{r tips}

# Ein Tip, wie man einen Datensatz ohne die Piraten kreiert, die sich "andersgeschlechtlich" bezeichnen:

mf_pirates <- subset(pirates, sex != "other")

# ggplot-cheatsheet: https://www.rstudio.com/wp-content/uploads/2015/06/ggplot2-german.pdf

```
